{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hJTqkUK_G_k"
      },
      "outputs": [],
      "source": [
        "print(\"Memulai proses setup...\")\n",
        "\n",
        "# Pindah ke direktori konten utama\n",
        "%cd /content\n",
        "\n",
        "# Clone repository ComfyUI dan custom node\n",
        "print(\"Cloning repository ComfyUI dan custom nodes...\")\n",
        "!git clone https://github.com/comfyanonymous/ComfyUI /content/ComfyUI -q\n",
        "!git clone https://github.com/city96/ComfyUI-GGUF /content/ComfyUI/custom_nodes/ComfyUI-GGUF -q\n",
        "\n",
        "# Pindah ke direktori ComfyUI\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "print(\"Menginstal dependensi yang diperlukan...\")\n",
        "!pip install -r requirements.txt accelerate torchsde gradio gguf -q\n",
        "print(\"Instalasi dependensi selesai.\")\n",
        "\n",
        "# Instal aria2 untuk mempercepat unduhan\n",
        "!apt install aria2 -qqy\n",
        "\n",
        "# Download model-model yang diperlukan menggunakan aria2\n",
        "print(\"Mengunduh model Unet...\")\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/QuantStack/Wan2.2-T2V-A14B-GGUF/resolve/main/LowNoise/Wan2.2-T2V-A14B-LowNoise-Q3_K_S.gguf -d /content/ComfyUI/models/unet -o Wan2.2-T2V-A14B-LowNoise-Q3_K_S.gguf\n",
        "\n",
        "print(\"Mengunduh model CLIP Encoder...\")\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/city96/umt5-xxl-encoder-gguf/resolve/main/umt5-xxl-encoder-Q3_K_S.gguf -d /content/ComfyUI/models/clip -o umt5-xxl-encoder-Q3_K_S.gguf\n",
        "\n",
        "print(\"Mengunduh model VAE...\")\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors -d /content/ComfyUI/models/vae -o wan_2.1_vae.safetensors\n",
        "\n",
        "print(\"Mengunduh model LoRA...\")\n",
        "!mkdir -p /content/ComfyUI/models/loras/FusionX\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX/resolve/main/FusionX_LoRa/Wan2.1_T2V_14B_FusionX_LoRA.safetensors -d /content/ComfyUI/models/loras/FusionX -o Wan2.1_T2V_14B_FusionX_LoRA.safetensors\n",
        "\n",
        "print(\"Setup selesai!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMemulai inisialisasi Python...\")\n",
        "\n",
        "# --- Instalasi library yang dibutuhkan jika belum ada ---\n",
        "# nest_asyncio diperlukan untuk menjalankan asyncio di dalam Colab/Jupyter\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    print(\"Menginstal nest_asyncio...\")\n",
        "    !pip install -q nest_asyncio\n",
        "    import nest_asyncio\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import os\n",
        "import asyncio\n",
        "\n",
        "# Terapkan patch asyncio agar bisa berjalan di dalam event loop Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Navigasi Direktori ---\n",
        "# Pastikan kita berada di direktori yang benar\n",
        "try:\n",
        "    os.chdir('/content/ComfyUI')\n",
        "    print(f\"Berpindah ke direktori: {os.getcwd()}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Sudah berada di direktori {os.getcwd()} atau direktori ComfyUI tidak ditemukan.\")\n",
        "\n",
        "\n",
        "# --- Pemuatan Asynchronous Custom Nodes ---\n",
        "# Import dilakukan di dalam fungsi async untuk memastikan lingkungan sudah siap\n",
        "async def load_custom_nodes():\n",
        "    \"\"\"\n",
        "    Memuat semua custom node yang dibutuhkan secara asynchronous.\n",
        "    \"\"\"\n",
        "    print(\"Memulai pemuatan custom nodes...\")\n",
        "    from nodes import load_custom_node\n",
        "    # Path harus absolut atau relatif dari direktori kerja saat ini\n",
        "    custom_node_path = os.path.join(os.getcwd(), \"custom_nodes\", \"ComfyUI-GGUF\")\n",
        "    if not os.path.isdir(custom_node_path):\n",
        "        print(f\"!!! WARNING: Direktori custom node tidak ditemukan di {custom_node_path}\")\n",
        "        return\n",
        "    await load_custom_node(custom_node_path)\n",
        "    print(\"Custom nodes berhasil dimuat.\")\n",
        "\n",
        "# Jalankan pemuatan custom node menggunakan asyncio.run() yang sekarang aman digunakan\n",
        "# berkat nest_asyncio.\n",
        "print(\"Menjalankan pemuatan custom node...\")\n",
        "asyncio.run(load_custom_nodes())\n",
        "\n",
        "\n",
        "# --- Import dan Inisialisasi Model Utama ---\n",
        "# Import class setelah custom node dipastikan telah dimuat\n",
        "from nodes import NODE_CLASS_MAPPINGS, KSamplerAdvanced, VAEDecode, CLIPTextEncode, EmptyLatentImage, VAELoader, LoraLoaderModelOnly\n",
        "import comfy.samplers\n",
        "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
        "\n",
        "print(\"Menginisialisasi class-class node...\")\n",
        "try:\n",
        "    UnetLoaderGGUF = NODE_CLASS_MAPPINGS[\"UnetLoaderGGUF\"]()\n",
        "    CLIPLoaderGGUF = NODE_CLASS_MAPPINGS[\"CLIPLoaderGGUF\"]()\n",
        "except KeyError as e:\n",
        "    print(f\"FATAL ERROR: Gagal menemukan node '{e.args[0]}'.\")\n",
        "    print(\"Pastikan custom node 'ComfyUI-GGUF' terinstal dengan benar di direktori 'custom_nodes' dan telah dimuat.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Inisialisasi node bawaan\n",
        "vae_loader = VAELoader()\n",
        "lora_loader = LoraLoaderModelOnly()\n",
        "\n",
        "print(\"\\nMemuat model utama (Unet, CLIP, VAE)...\")\n",
        "try:\n",
        "    unet_model = UnetLoaderGGUF.load_unet(\"Wan2.2-T2V-A14B-LowNoise-Q3_K_S.gguf\")[0]\n",
        "    clip_model = CLIPLoaderGGUF.load_clip(\"umt5-xxl-encoder-Q3_K_S.gguf\", \"wan\")[0]\n",
        "    vae_model = vae_loader.load_vae(\"wan_2.1_vae.safetensors\")[0]\n",
        "\n",
        "    print(\"Memuat model LoRA...\")\n",
        "    lora_model = lora_loader.load_lora_model_only(unet_model, \"FusionX/Wan2.1_T2V_14B_FusionX_LoRA.safetensors\", 1.0)[0]\n",
        "    print(\"Semua model berhasil dimuat!\")\n",
        "except Exception as e:\n",
        "    print(f\"!!! FATAL ERROR SAAT MEMUAT MODEL: {e} !!!\")\n",
        "    print(\"Pastikan nama file model dan path-nya sudah benar dan file tersebut ada di direktori 'ComfyUI/models/'.\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "# --- Fungsi Generate Gambar ---\n",
        "def generate_image(positive_prompt, negative_prompt, width, height, steps, cfg, seed, sampler_name, scheduler):\n",
        "    \"\"\"\n",
        "    Fungsi utama untuk menghasilkan gambar berdasarkan input dari antarmuka Gradio.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Memulai Proses Generate Gambar ---\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Inisialisasi node yang dibutuhkan di dalam fungsi untuk state yang bersih\n",
        "        clip_text_encode = CLIPTextEncode()\n",
        "        empty_latent_image = EmptyLatentImage()\n",
        "        k_sampler_advanced = KSamplerAdvanced()\n",
        "        vae_decode = VAEDecode()\n",
        "        model_sampler_patcher = ModelSamplingSD3()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            print(\"-> Melakukan encoding pada prompt...\")\n",
        "            positive_conditioning = clip_text_encode.encode(clip_model, positive_prompt)[0]\n",
        "            negative_conditioning = clip_text_encode.encode(clip_model, negative_prompt)[0]\n",
        "\n",
        "            print(\"-> Melakukan patch pada model dengan sampler...\")\n",
        "            model_with_sampler = model_sampler_patcher.patch(lora_model, 1.0)[0]\n",
        "\n",
        "            print(f\"-> Membuat latent kosong dengan ukuran {width}x{height}...\")\n",
        "            latent_image = empty_latent_image.generate(width, height, 1)[0]\n",
        "\n",
        "            if int(seed) == -1:\n",
        "                seed = random.randint(0, 2**64 - 1)\n",
        "            print(f\"-> Menggunakan Seed: {seed}\")\n",
        "\n",
        "            print(f\"-> Menjalankan KSampler dengan {steps} steps...\")\n",
        "            samples = k_sampler_advanced.sample(\n",
        "                model=model_with_sampler, add_noise=\"enable\", noise_seed=int(seed), steps=int(steps),\n",
        "                cfg=cfg, sampler_name=sampler_name, scheduler=scheduler,\n",
        "                positive=positive_conditioning, negative=negative_conditioning, latent_image=latent_image,\n",
        "                start_at_step=0, end_at_step=9999, return_with_leftover_noise=\"disable\"\n",
        "            )[0]\n",
        "\n",
        "            print(\"-> Melakukan decode pada hasil sample menjadi gambar...\")\n",
        "            decoded_image_tensor = vae_decode.decode(vae_model, samples)[0]\n",
        "\n",
        "            # Konversi tensor ke PIL Image\n",
        "            image_np = decoded_image_tensor.cpu().numpy()\n",
        "            image_np_uint8 = (image_np.clip(0, 1) * 255).astype(np.uint8)\n",
        "            final_image = Image.fromarray(image_np_uint8[0])\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"--- Proses Generate Gambar Selesai (Durasi: {end_time - start_time:.2f} detik) ---\")\n",
        "\n",
        "            return final_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!!! TERJADI ERROR SAAT GENERATE GAMBAR: {e} !!!\")\n",
        "        traceback.print_exc()\n",
        "        # Mengembalikan gambar kosong atau placeholder jika terjadi error\n",
        "        return Image.new('RGB', (512, 512), color = 'red')\n",
        "\n",
        "\n",
        "# --- Antarmuka Gradio ---\n",
        "print(\"\\nMenyiapkan antarmuka Gradio...\")\n",
        "\n",
        "with gr.Blocks(css=\"footer {display: none !important}\") as demo:\n",
        "    gr.Markdown(\"## ComfyUI GGUF Image Generator\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            positive_prompt = gr.Textbox(label=\"Positive Prompt\", lines=3, placeholder=\"Contoh: a cinematic photo of a majestic lion...\")\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", lines=3, value=\"blurry, low quality, static, frame, text, watermark\")\n",
        "            with gr.Row():\n",
        "                sampler_name = gr.Dropdown(label=\"Sampler\", choices=comfy.samplers.KSampler.SAMPLERS, value=\"euler_ancestral\")\n",
        "                scheduler = gr.Dropdown(label=\"Scheduler\", choices=comfy.samplers.KSampler.SCHEDULERS, value=\"normal\")\n",
        "            with gr.Row():\n",
        "                width = gr.Slider(label=\"Width\", minimum=256, maximum=1920, value=1024, step=64)\n",
        "                height = gr.Slider(label=\"Height\", minimum=256, maximum=1080, value=576, step=64)\n",
        "            with gr.Row():\n",
        "                steps = gr.Slider(label=\"Steps\", minimum=1, maximum=20, value=10, step=1)\n",
        "                cfg = gr.Slider(label=\"CFG Scale\", minimum=0.0, maximum=15.0, value=3.5, step=0.5)\n",
        "            seed = gr.Number(label=\"Seed (-1 untuk acak)\", value=-1, precision=0)\n",
        "            generate_button = gr.Button(\"Generate\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            output_image = gr.Image(label=\"Generated Image\", type=\"pil\", format=\"png\", height=512)\n",
        "\n",
        "    inputs = [positive_prompt, negative_prompt, width, height, steps, cfg, seed, sampler_name, scheduler]\n",
        "    generate_button.click(fn=generate_image, inputs=inputs, outputs=[output_image], api_name=\"generate\")\n",
        "\n",
        "print(\"\\nMeluncurkan antarmuka Gradio...\")\n",
        "demo.launch(share=True, inline=False, debug=True)"
      ],
      "metadata": {
        "id": "58M8483zYeB5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}